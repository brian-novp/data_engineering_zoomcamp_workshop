{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfbca452-d499-40d1-a586-7215663f859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9231b78f-3472-4500-8758-c3e54a2a7c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bri/zoomcamp/data_engineering_zoomcamp_workshop/01-docker-terraform/pipeline\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a557c70a-c29c-4372-b6a4-08c916baa030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- -----------\n",
      "anyio                     4.12.1\n",
      "argon2-cffi               25.1.0\n",
      "argon2-cffi-bindings      25.1.0\n",
      "arrow                     1.4.0\n",
      "asttokens                 3.0.1\n",
      "async-lru                 2.1.0\n",
      "attrs                     25.4.0\n",
      "babel                     2.17.0\n",
      "beautifulsoup4            4.14.3\n",
      "bleach                    6.3.0\n",
      "certifi                   2026.1.4\n",
      "cffi                      2.0.0\n",
      "charset-normalizer        3.4.4\n",
      "cli-helpers               2.8.2\n",
      "click                     8.1.7\n",
      "comm                      0.2.3\n",
      "configobj                 5.0.9\n",
      "debugpy                   1.8.19\n",
      "decorator                 5.2.1\n",
      "defusedxml                0.7.1\n",
      "executing                 2.2.1\n",
      "fastjsonschema            2.21.2\n",
      "fqdn                      1.5.1\n",
      "greenlet                  3.3.1\n",
      "h11                       0.16.0\n",
      "httpcore                  1.0.9\n",
      "httpx                     0.28.1\n",
      "idna                      3.11\n",
      "ipykernel                 7.1.0\n",
      "ipython                   9.9.0\n",
      "ipython-pygments-lexers   1.1.1\n",
      "ipywidgets                8.1.8\n",
      "isoduration               20.11.0\n",
      "jedi                      0.19.2\n",
      "jinja2                    3.1.6\n",
      "json5                     0.13.0\n",
      "jsonpointer               3.0.0\n",
      "jsonschema                4.26.0\n",
      "jsonschema-specifications 2025.9.1\n",
      "jupyter                   1.1.1\n",
      "jupyter-client            8.8.0\n",
      "jupyter-console           6.6.3\n",
      "jupyter-core              5.9.1\n",
      "jupyter-events            0.12.0\n",
      "jupyter-lsp               2.3.0\n",
      "jupyter-server            2.17.0\n",
      "jupyter-server-terminals  0.5.4\n",
      "jupyterlab                4.5.3\n",
      "jupyterlab-pygments       0.3.0\n",
      "jupyterlab-server         2.28.0\n",
      "jupyterlab-widgets        3.0.16\n",
      "lark                      1.3.1\n",
      "markupsafe                3.0.3\n",
      "matplotlib-inline         0.2.1\n",
      "mistune                   3.2.0\n",
      "nbclient                  0.10.4\n",
      "nbconvert                 7.16.6\n",
      "nbformat                  5.10.4\n",
      "nest-asyncio              1.6.0\n",
      "notebook                  7.5.3\n",
      "notebook-shim             0.2.4\n",
      "numpy                     2.4.1\n",
      "packaging                 26.0\n",
      "pandas                    3.0.0\n",
      "pandocfilters             1.5.1\n",
      "parso                     0.8.5\n",
      "pexpect                   4.9.0\n",
      "pgcli                     4.4.0\n",
      "pgspecial                 2.2.1\n",
      "platformdirs              4.5.1\n",
      "prometheus-client         0.24.1\n",
      "prompt-toolkit            3.0.52\n",
      "psutil                    7.2.1\n",
      "psycopg                   3.3.2\n",
      "psycopg2-binary           2.9.11\n",
      "ptyprocess                0.7.0\n",
      "pure-eval                 0.2.3\n",
      "pyarrow                   23.0.0\n",
      "pycparser                 3.0\n",
      "pygments                  2.19.2\n",
      "python-dateutil           2.9.0.post0\n",
      "python-json-logger        4.0.0\n",
      "pyyaml                    6.0.3\n",
      "pyzmq                     27.1.0\n",
      "referencing               0.37.0\n",
      "requests                  2.32.5\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rfc3987-syntax            1.1.0\n",
      "rpds-py                   0.30.0\n",
      "send2trash                2.1.0\n",
      "setproctitle              1.3.7\n",
      "setuptools                80.10.2\n",
      "six                       1.17.0\n",
      "soupsieve                 2.8.3\n",
      "sqlalchemy                2.0.46\n",
      "sqlparse                  0.5.5\n",
      "stack-data                0.6.3\n",
      "tabulate                  0.9.0\n",
      "terminado                 0.18.1\n",
      "tinycss2                  1.4.0\n",
      "tornado                   6.5.4\n",
      "tqdm                      4.67.1\n",
      "traitlets                 5.14.3\n",
      "typing-extensions         4.15.0\n",
      "tzdata                    2025.3\n",
      "tzlocal                   5.3.1\n",
      "uri-template              1.3.0\n",
      "urllib3                   2.6.3\n",
      "wcwidth                   0.4.0\n",
      "webcolors                 25.10.0\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.9.0\n",
      "widgetsnbextension        4.0.15\n"
     ]
    }
   ],
   "source": [
    "!uv pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68fd8a30-4c62-471a-90bc-a1d75c93d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2025-11.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecdb2ad4-0c75-4fa5-acd1-43480dbefcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
      "0         2  2025-11-01 00:34:48   2025-11-01 00:41:39                  N   \n",
      "1         2  2025-11-01 00:18:52   2025-11-01 00:24:27                  N   \n",
      "2         2  2025-11-01 01:03:14   2025-11-01 01:15:24                  N   \n",
      "3         2  2025-11-01 00:10:57   2025-11-01 00:24:53                  N   \n",
      "4         1  2025-11-01 00:03:48   2025-11-01 00:19:38                  N   \n",
      "\n",
      "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
      "0         1.0            74            42              1.0           0.74   \n",
      "1         1.0            74            42              2.0           0.95   \n",
      "2         1.0            83           160              1.0           2.19   \n",
      "3         1.0           166           127              1.0           5.44   \n",
      "4         1.0           166           262              1.0           3.20   \n",
      "\n",
      "   fare_amount  ...  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
      "0          7.2  ...      0.5        1.94           0.0        NaN   \n",
      "1          7.2  ...      0.5        0.00           0.0        NaN   \n",
      "2         13.5  ...      0.5        5.00           0.0        NaN   \n",
      "3         24.7  ...      0.5        0.50           0.0        NaN   \n",
      "4         18.4  ...      1.5        1.00           0.0        NaN   \n",
      "\n",
      "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
      "0                    1.0         11.64           1.0        1.0   \n",
      "1                    1.0          9.70           2.0        1.0   \n",
      "2                    1.0         21.00           1.0        1.0   \n",
      "3                    1.0         27.70           1.0        1.0   \n",
      "4                    1.0         24.65           1.0        1.0   \n",
      "\n",
      "   congestion_surcharge  cbd_congestion_fee  \n",
      "0                  0.00                 0.0  \n",
      "1                  0.00                 0.0  \n",
      "2                  0.00                 0.0  \n",
      "3                  0.00                 0.0  \n",
      "4                  2.75                 0.0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_trip = pd.read_parquet(url)\n",
    "    print(df_trip.head())\n",
    "except ImportError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Please install pyarrow or fastparquet to read parquet files.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5c31361-1860-4d13-8683-040d47509436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 46912 entries, 0 to 46911\n",
      "Data columns (total 21 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   VendorID               46912 non-null  int32         \n",
      " 1   lpep_pickup_datetime   46912 non-null  datetime64[us]\n",
      " 2   lpep_dropoff_datetime  46912 non-null  datetime64[us]\n",
      " 3   store_and_fwd_flag     41343 non-null  str           \n",
      " 4   RatecodeID             41343 non-null  float64       \n",
      " 5   PULocationID           46912 non-null  int32         \n",
      " 6   DOLocationID           46912 non-null  int32         \n",
      " 7   passenger_count        41343 non-null  float64       \n",
      " 8   trip_distance          46912 non-null  float64       \n",
      " 9   fare_amount            46912 non-null  float64       \n",
      " 10  extra                  46912 non-null  float64       \n",
      " 11  mta_tax                46912 non-null  float64       \n",
      " 12  tip_amount             46912 non-null  float64       \n",
      " 13  tolls_amount           46912 non-null  float64       \n",
      " 14  ehail_fee              0 non-null      float64       \n",
      " 15  improvement_surcharge  46912 non-null  float64       \n",
      " 16  total_amount           46912 non-null  float64       \n",
      " 17  payment_type           41343 non-null  float64       \n",
      " 18  trip_type              41342 non-null  float64       \n",
      " 19  congestion_surcharge   41343 non-null  float64       \n",
      " 20  cbd_congestion_fee     46912 non-null  float64       \n",
      "dtypes: datetime64[us](2), float64(15), int32(3), str(1)\n",
      "memory usage: 7.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_trip.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bf9a0b7-cf00-4b78-be6e-9f1e79bc7acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_zones = 'https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69920eca-9fb6-4144-a5be-ab758e86da4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LocationID        Borough                     Zone service_zone\n",
      "0           1            EWR           Newark Airport          EWR\n",
      "1           2         Queens              Jamaica Bay    Boro Zone\n",
      "2           3          Bronx  Allerton/Pelham Gardens    Boro Zone\n",
      "3           4      Manhattan            Alphabet City  Yellow Zone\n",
      "4           5  Staten Island            Arden Heights    Boro Zone\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_zones = pd.read_csv(url_zones)\n",
    "    print(df_zones.head())\n",
    "except ImportError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Please install pyarrow or fastparquet to read parquet files.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02aad93c-2300-4240-a713-d00391d60c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 265 entries, 0 to 264\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype\n",
      "---  ------        --------------  -----\n",
      " 0   LocationID    265 non-null    int64\n",
      " 1   Borough       265 non-null    str  \n",
      " 2   Zone          264 non-null    str  \n",
      " 3   service_zone  263 non-null    str  \n",
      "dtypes: int64(1), str(3)\n",
      "memory usage: 16.9 KB\n"
     ]
    }
   ],
   "source": [
    "df_zones.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f7b4408-5798-454c-983f-64f11bce6a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Column: LocationID ---\n",
      "LocationID\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "5      1\n",
      "      ..\n",
      "261    1\n",
      "262    1\n",
      "263    1\n",
      "264    1\n",
      "265    1\n",
      "Name: count, Length: 265, dtype: int64\n",
      "\n",
      "\n",
      "--- Column: Borough ---\n",
      "Borough\n",
      "Queens           69\n",
      "Manhattan        69\n",
      "Brooklyn         61\n",
      "Bronx            43\n",
      "Staten Island    20\n",
      "Unknown           2\n",
      "EWR               1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "--- Column: Zone ---\n",
      "Zone\n",
      "Governor's Island/Ellis Island/Liberty Island    3\n",
      "Corona                                           2\n",
      "Newark Airport                                   1\n",
      "Jamaica Bay                                      1\n",
      "Allerton/Pelham Gardens                          1\n",
      "                                                ..\n",
      "Woodside                                         1\n",
      "World Trade Center                               1\n",
      "Yorkville East                                   1\n",
      "Yorkville West                                   1\n",
      "NV                                               1\n",
      "Name: count, Length: 261, dtype: int64\n",
      "\n",
      "\n",
      "--- Column: service_zone ---\n",
      "service_zone\n",
      "Boro Zone      205\n",
      "Yellow Zone     55\n",
      "Airports         2\n",
      "EWR              1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in df_zones.columns:\n",
    "    print(f\"--- Column: {col} ---\")\n",
    "    print(df_zones[col].value_counts())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b64cf6a7-e26d-4e88-9f4a-fbdafa7501b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_data_check_with_names(datasets, dataset_names):\n",
    "    \"\"\"\n",
    "    Function to display missing values, percentage of missing values, \n",
    "    duplicated data, total number of rows, and dtype of each column \n",
    "    for multiple datasets.\n",
    "    \n",
    "    :param datasets: A list of pandas dataframes to check.\n",
    "    :param dataset_names: A list of dataset names corresponding to each dataframe.\n",
    "    :return: A summary dataframe with the details for all datasets.\n",
    "    \"\"\"\n",
    "    \n",
    "    summary_list = []  # To store details for each dataset\n",
    "    \n",
    "    for i, data in enumerate(datasets):\n",
    "        # Get the name of the dataset from the passed dataset_names list\n",
    "        dataset_name = dataset_names[i] if i < len(dataset_names) else f'Dataset_{i+1}'\n",
    "        \n",
    "        # For each dataset, we compute the necessary details\n",
    "        null_counts = data.isnull().sum()\n",
    "        null_percentage = (null_counts / len(data)) * 100\n",
    "        dup_count = data.duplicated().sum()\n",
    "        dtypes = data.dtypes\n",
    "        total_rows = len(data)  # Total number of rows\n",
    "        \n",
    "        # Create a temporary DataFrame to store the results for this dataset\n",
    "        temp_df = pd.DataFrame({\n",
    "            'Dataset': dataset_name,\n",
    "            'Column': data.columns,\n",
    "            'Data Type': dtypes.values,\n",
    "            'Missing Values': null_counts.values,\n",
    "            'Percentage Missing': null_percentage.values,\n",
    "            'Total Rows': [total_rows] * len(data.columns),\n",
    "            'Duplicate Rows': [dup_count] * len(data.columns)  # same for all columns\n",
    "                 # same for all columns\n",
    "            \n",
    "        })\n",
    "        \n",
    "        # Append the result to the summary list\n",
    "        summary_list.append(temp_df)\n",
    "    \n",
    "    # Concatenate all summaries into one DataFrame\n",
    "    final_summary = pd.concat(summary_list, ignore_index=True)\n",
    "    \n",
    "    return final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aacbc27-8e1c-463d-a7d6-0097aeb6abd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [df_trip, df_zones]\n",
    "names = ['df_trip', 'df_zones']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "983fdf79-1433-420e-8bd6-4c9bdc188d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Column</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Percentage Missing</th>\n",
       "      <th>Total Rows</th>\n",
       "      <th>Duplicate Rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>df_trip</td>\n",
       "      <td>VendorID</td>\n",
       "      <td>int32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>df_trip</td>\n",
       "      <td>lpep_pickup_datetime</td>\n",
       "      <td>datetime64[us]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>df_trip</td>\n",
       "      <td>lpep_dropoff_datetime</td>\n",
       "      <td>datetime64[us]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>df_trip</td>\n",
       "      <td>store_and_fwd_flag</td>\n",
       "      <td>str</td>\n",
       "      <td>5569</td>\n",
       "      <td>11.871163</td>\n",
       "      <td>46912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>df_trip</td>\n",
       "      <td>RatecodeID</td>\n",
       "      <td>float64</td>\n",
       "      <td>5569</td>\n",
       "      <td>11.871163</td>\n",
       "      <td>46912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>df_trip</td>\n",
       "      <td>PULocationID</td>\n",
       "      <td>int32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>df_trip</td>\n",
       "      <td>DOLocationID</td>\n",
       "      <td>int32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>df_trip</td>\n",
       "      <td>passenger_count</td>\n",
       "      <td>float64</td>\n",
       "      <td>5569</td>\n",
       "      <td>11.871163</td>\n",
       "      <td>46912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>df_trip</td>\n",
       "      <td>trip_distance</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>df_trip</td>\n",
       "      <td>fare_amount</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>df_trip</td>\n",
       "      <td>extra</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>df_trip</td>\n",
       "      <td>mta_tax</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>df_trip</td>\n",
       "      <td>tip_amount</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>df_trip</td>\n",
       "      <td>tolls_amount</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>df_trip</td>\n",
       "      <td>ehail_fee</td>\n",
       "      <td>float64</td>\n",
       "      <td>46912</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>46912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>df_trip</td>\n",
       "      <td>improvement_surcharge</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>df_trip</td>\n",
       "      <td>total_amount</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>df_trip</td>\n",
       "      <td>payment_type</td>\n",
       "      <td>float64</td>\n",
       "      <td>5569</td>\n",
       "      <td>11.871163</td>\n",
       "      <td>46912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>df_trip</td>\n",
       "      <td>trip_type</td>\n",
       "      <td>float64</td>\n",
       "      <td>5570</td>\n",
       "      <td>11.873295</td>\n",
       "      <td>46912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>df_trip</td>\n",
       "      <td>congestion_surcharge</td>\n",
       "      <td>float64</td>\n",
       "      <td>5569</td>\n",
       "      <td>11.871163</td>\n",
       "      <td>46912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>df_trip</td>\n",
       "      <td>cbd_congestion_fee</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>df_zones</td>\n",
       "      <td>LocationID</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>df_zones</td>\n",
       "      <td>Borough</td>\n",
       "      <td>str</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>df_zones</td>\n",
       "      <td>Zone</td>\n",
       "      <td>str</td>\n",
       "      <td>1</td>\n",
       "      <td>0.377358</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>df_zones</td>\n",
       "      <td>service_zone</td>\n",
       "      <td>str</td>\n",
       "      <td>2</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset                 Column       Data Type  Missing Values  \\\n",
       "0    df_trip               VendorID           int32               0   \n",
       "1    df_trip   lpep_pickup_datetime  datetime64[us]               0   \n",
       "2    df_trip  lpep_dropoff_datetime  datetime64[us]               0   \n",
       "3    df_trip     store_and_fwd_flag             str            5569   \n",
       "4    df_trip             RatecodeID         float64            5569   \n",
       "5    df_trip           PULocationID           int32               0   \n",
       "6    df_trip           DOLocationID           int32               0   \n",
       "7    df_trip        passenger_count         float64            5569   \n",
       "8    df_trip          trip_distance         float64               0   \n",
       "9    df_trip            fare_amount         float64               0   \n",
       "10   df_trip                  extra         float64               0   \n",
       "11   df_trip                mta_tax         float64               0   \n",
       "12   df_trip             tip_amount         float64               0   \n",
       "13   df_trip           tolls_amount         float64               0   \n",
       "14   df_trip              ehail_fee         float64           46912   \n",
       "15   df_trip  improvement_surcharge         float64               0   \n",
       "16   df_trip           total_amount         float64               0   \n",
       "17   df_trip           payment_type         float64            5569   \n",
       "18   df_trip              trip_type         float64            5570   \n",
       "19   df_trip   congestion_surcharge         float64            5569   \n",
       "20   df_trip     cbd_congestion_fee         float64               0   \n",
       "21  df_zones             LocationID           int64               0   \n",
       "22  df_zones                Borough             str               0   \n",
       "23  df_zones                   Zone             str               1   \n",
       "24  df_zones           service_zone             str               2   \n",
       "\n",
       "    Percentage Missing  Total Rows  Duplicate Rows  \n",
       "0             0.000000       46912               0  \n",
       "1             0.000000       46912               0  \n",
       "2             0.000000       46912               0  \n",
       "3            11.871163       46912               0  \n",
       "4            11.871163       46912               0  \n",
       "5             0.000000       46912               0  \n",
       "6             0.000000       46912               0  \n",
       "7            11.871163       46912               0  \n",
       "8             0.000000       46912               0  \n",
       "9             0.000000       46912               0  \n",
       "10            0.000000       46912               0  \n",
       "11            0.000000       46912               0  \n",
       "12            0.000000       46912               0  \n",
       "13            0.000000       46912               0  \n",
       "14          100.000000       46912               0  \n",
       "15            0.000000       46912               0  \n",
       "16            0.000000       46912               0  \n",
       "17           11.871163       46912               0  \n",
       "18           11.873295       46912               0  \n",
       "19           11.871163       46912               0  \n",
       "20            0.000000       46912               0  \n",
       "21            0.000000         265               0  \n",
       "22            0.000000         265               0  \n",
       "23            0.377358         265               0  \n",
       "24            0.754717         265               0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_data_check_with_names(dataset, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abc62df-abd1-40ac-b146-f88d521c9e64",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Insights from multiple data check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57692ccf-ddf8-470f-9bab-cbc9c22440e7",
   "metadata": {},
   "source": [
    "1. 'ehail_fee' column in df_trip has 100% missing data. After consulting with software engineers and business people, it is a valid feature for green taxi after court decision in 2013. So we keep it as is.\n",
    "2. Meanwhile, these 6 columns in df_trip that have 11% to 12% missing values are to be kept as they are. We can analyze further if there are patterns emerge from those missing values : Whether specific areas have higher missing values. This can start a business process investigation.\n",
    "   - store_and_fwd_flag\n",
    "   - RatecodeID\n",
    "   - passenger_count\n",
    "   - payment_type\n",
    "   - trip_type\n",
    "   - congestion_surcharge\n",
    "4. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c1a2ed-ce4b-4912-940b-bdc7a7e1f244",
   "metadata": {},
   "source": [
    "# Change data type to the correct dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2ea754-e746-4b24-8e38-84cd9b94322c",
   "metadata": {},
   "source": [
    "- pd.read_parquet doesn't have parse_date like read_csv.\n",
    "- When you use pandas.read_parquet, the data types (dtypes) are typically inferred automatically from the metadata stored within the Parquet file itself. The Parquet format is a columnar storage format that preserves data types, unlike formats like CSV which require type inference.\n",
    "- The primary behavior of read_parquet is to read the data using its inherent type information. The underlying engine (by default, pyarrow) handles the conversion from the Parquet data types to the corresponding pandas/NumPy types\n",
    "- So we use .astype({'col_1': 'int64', 'col_2': 'category'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3a40860-e10d-4adb-806c-feba5118ac91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RatecodeID\n",
       "1.0     38725\n",
       "5.0      2432\n",
       "2.0       112\n",
       "4.0        53\n",
       "3.0        20\n",
       "99.0        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trip[\"RatecodeID\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "031e02c3-e94d-45f0-a539-d3b1f3c9c955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'lpep_pickup_datetime', 'lpep_dropoff_datetime',\n",
       "       'store_and_fwd_flag', 'RatecodeID', 'PULocationID', 'DOLocationID',\n",
       "       'passenger_count', 'trip_distance', 'fare_amount', 'extra', 'mta_tax',\n",
       "       'tip_amount', 'tolls_amount', 'ehail_fee', 'improvement_surcharge',\n",
       "       'total_amount', 'payment_type', 'trip_type', 'congestion_surcharge',\n",
       "       'cbd_congestion_fee'],\n",
       "      dtype='str')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trip.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a358c67-e2f6-4b51-ba9d-e4394ef04b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trip = df_trip.astype({\n",
    "    \"VendorID\": \"str\",#changed from int32\n",
    "    \"lpep_pickup_datetime\" : \"datetime64[us]\",\n",
    "    \"lpep_dropoff_datetime\": \"datetime64[us]\",\n",
    "    \"store_and_fwd_flag\": \"str\",\n",
    "    \"RatecodeID\": \"float64\", #did not change because it behaved weird in postgresql\n",
    "    \"PULocationID\": \"str\",\n",
    "    \"DOLocationID\": \"str\",\n",
    "    \"passenger_count\": \"Int64\",\n",
    "    \"trip_distance\": \"float64\",\n",
    "    \"fare_amount\": \"float64\",\n",
    "    \"extra\": \"float64\",\n",
    "    \"mta_tax\": \"float64\",\n",
    "    \"tip_amount\": \"float64\",\n",
    "    \"tolls_amount\": \"float64\",\n",
    "    \"ehail_fee\" : \"float64\",\n",
    "    \"improvement_surcharge\": \"float64\",\n",
    "    \"total_amount\": \"float64\",\n",
    "    \"payment_type\": \"Int64\", #did not change because it behaved weird in postgresql\n",
    "    \"trip_type\" : \"float64\", #did not change because it behaved weird in postgresql\n",
    "    \"congestion_surcharge\": \"float64\",\n",
    "    \"cbd_congestion_fee\" : \"float64\"\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1af5fcea-2e30-4c7e-9dbb-81c32ce40d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 46912 entries, 0 to 46911\n",
      "Data columns (total 21 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   VendorID               46912 non-null  str           \n",
      " 1   lpep_pickup_datetime   46912 non-null  datetime64[us]\n",
      " 2   lpep_dropoff_datetime  46912 non-null  datetime64[us]\n",
      " 3   store_and_fwd_flag     41343 non-null  str           \n",
      " 4   RatecodeID             41343 non-null  float64       \n",
      " 5   PULocationID           46912 non-null  str           \n",
      " 6   DOLocationID           46912 non-null  str           \n",
      " 7   passenger_count        41343 non-null  Int64         \n",
      " 8   trip_distance          46912 non-null  float64       \n",
      " 9   fare_amount            46912 non-null  float64       \n",
      " 10  extra                  46912 non-null  float64       \n",
      " 11  mta_tax                46912 non-null  float64       \n",
      " 12  tip_amount             46912 non-null  float64       \n",
      " 13  tolls_amount           46912 non-null  float64       \n",
      " 14  ehail_fee              0 non-null      float64       \n",
      " 15  improvement_surcharge  46912 non-null  float64       \n",
      " 16  total_amount           46912 non-null  float64       \n",
      " 17  payment_type           41343 non-null  Int64         \n",
      " 18  trip_type              41342 non-null  float64       \n",
      " 19  congestion_surcharge   41343 non-null  float64       \n",
      " 20  cbd_congestion_fee     46912 non-null  float64       \n",
      "dtypes: Int64(2), datetime64[us](2), float64(13), str(4)\n",
      "memory usage: 7.9 MB\n"
     ]
    }
   ],
   "source": [
    "df_trip.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa6e6f25-818c-4126-b612-f01bd6c4691a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LocationID', 'Borough', 'Zone', 'service_zone'], dtype='str')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zones.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34003a78-1dba-4629-808e-e0c7ba92810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = df_zones.astype({'LocationID' : \"str\", \n",
    "                            'Borough' : \"str\", \n",
    "                            'Zone' : \"str\", \n",
    "                            'service_zone' : \"str\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e857cd-c981-48e1-986c-404ca35782ce",
   "metadata": {},
   "source": [
    "# Create database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b0ec206-a1c2-415e-93e5-793cecd85093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1667c2a0-b399-41e8-98e5-2627f4376444",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3adc33d-4dd9-45fa-99dd-92efccccb809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to PostgreSQL database successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        print(\"Connected to PostgreSQL database successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4097a4-24a2-44d9-ab3e-e0754c22881a",
   "metadata": {},
   "source": [
    "# Get DDL Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32e10b22-1e58-44c9-8db8-3bf5c4c9bf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE green_taxi_data (\n",
      "\t\"VendorID\" TEXT, \n",
      "\tlpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tlpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"RatecodeID\" FLOAT(53), \n",
      "\t\"PULocationID\" TEXT, \n",
      "\t\"DOLocationID\" TEXT, \n",
      "\tpassenger_count BIGINT, \n",
      "\ttrip_distance FLOAT(53), \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\tehail_fee FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tpayment_type BIGINT, \n",
      "\ttrip_type FLOAT(53), \n",
      "\tcongestion_surcharge FLOAT(53), \n",
      "\tcbd_congestion_fee FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(df_trip, name='green_taxi_data', con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30d71a1e-490e-45d2-9dd9-8d05dd0f5575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE taxi_zone (\n",
      "\t\"LocationID\" TEXT, \n",
      "\t\"Borough\" TEXT, \n",
      "\t\"Zone\" TEXT, \n",
      "\tservice_zone TEXT\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(df_zones, name='taxi_zone', con=engine))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9804a23-ceb3-4fe0-b4e9-66c244b8adf7",
   "metadata": {},
   "source": [
    "# Create Table in PostgreSQL without inserting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6416801-3ae9-4cbd-bfac-5d784f9ff5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trip.head(n=0).to_sql(name='green_taxi_data', con=engine, if_exists='replace')\n",
    "# head(n=0) ensure to create only table. no inserting any data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd01c506-0d03-47e3-869e-205fb4b6b66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zones.head(n=0).to_sql(name='taxi_zone', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894a8aca-e5aa-43d9-94ff-a6887b0062d1",
   "metadata": {},
   "source": [
    "# Inserting data to Postgre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1fca9a9-9ba2-4cc7-8d23-54ae7a9c1d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.3 s, sys: 72.4 ms, total: 2.37 s\n",
      "Wall time: 3.58 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "912"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_trip.to_sql(name='green_taxi_data', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a310a01-e537-4ae3-8050-d74b9f4d2126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.52 ms, sys: 0 ns, total: 8.52 ms\n",
      "Wall time: 14.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_zones.to_sql(name='taxi_zone', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a7d975-5549-4bd1-b3e3-f69dfd61596d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
